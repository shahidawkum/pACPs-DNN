{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNzjRs-FgpPr"
      },
      "outputs": [],
      "source": [
        "## Import necessary modules\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, matthews_corrcoef\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_val_score,KFold,cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JpYeJyt4gqDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "id": "ywHszLp1gsWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "PSmjyFzfgvpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Initialise the Scaler\n",
        "scaler = StandardScaler()\n",
        "# To scale data\n",
        "scaler.fit(df)"
      ],
      "metadata": {
        "id": "uoX7D2OrgxbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.fillna(999, inplace=True)"
      ],
      "metadata": {
        "id": "kA5J75eFgz19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X = df.iloc[:, 0:167].values\n",
        "y = df.iloc [:, 167].values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "CMpsd-omg1U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and test set\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "             X, y, test_size = 0.2, random_state=42)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "metadata": {
        "id": "TuE698q1g20M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, Dense, MaxPooling1D\n",
        "from keras.models import Model\n",
        "\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Define the attention mechanism as a custom layer\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        # Create the Dense layer for computing attention scores during initialization\n",
        "        self.attention_dense = Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Compute attention scores\n",
        "        attention_scores = self.attention_dense(inputs)\n",
        "        attention_weights = tf.keras.layers.Softmax(axis=1)(attention_scores)\n",
        "\n",
        "        # Apply attention weights to the input\n",
        "        weighted_inputs = inputs * attention_weights\n",
        "        return tf.reduce_sum(weighted_inputs, axis=1, keepdims=True)  # Ensure output is 2D\n",
        "\n",
        "# Define the model with an input layer\n",
        "inputs = Input(shape=(X_train.shape[1],))\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "# Apply the Attention Layer\n",
        "x = AttentionLayer()(x)\n",
        "\n",
        "# Now that the attention layer has output shape (None, 1), reshape it\n",
        "x = tf.keras.layers.Flatten()(x)  # Flatten to ensure it is 2D\n",
        "\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "accuracy_list = []\n",
        "f1_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "sensitivity_list = []\n",
        "specificity_list = []\n",
        "mcc_list = []\n",
        "auc_list = []  # Initialize a list for AUC values\n",
        "\n",
        "# Perform K-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=5)\n",
        "for train_index, val_index in kfold.split(X_train):\n",
        "    # Split the data into training and validation sets for the current fold\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train the model on the current fold\n",
        "    history=model.fit(X_train_fold, y_train_fold, epochs=40, batch_size=64, verbose=0,validation_split=0.1)\n",
        "\n",
        "    # Evaluate the model on the validation set for the current fold\n",
        "    y_val_pred = model.predict(X_val_fold)\n",
        "    y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
        "\n",
        "    # Calculate confusion matrix for the current fold\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_binary)\n",
        "    # Calculate AUC for the current fold\n",
        "    auc = roc_auc_score(y_val_fold, y_val_pred)  # Use predicted probabilities for AUC calculation\n",
        "    auc_list.append(auc)\n",
        "\n",
        "\n",
        "    # Calculate performance evaluation metrics for the current fold\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "    TP = cm[1, 1]\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "    accuracy_list.append(accuracy)\n",
        "\n",
        "    # F1-Score\n",
        "    f1 = 2 * TP / float(2 * TP + FP + FN)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    # Precision\n",
        "    precision = TP / float(TP + FP)\n",
        "    precision_list.append(precision)\n",
        "\n",
        "    # Recall\n",
        "    recall = TP / float(TP + FN)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "    # Sensitivity\n",
        "    sensitivity = TP / float(TP + FN)\n",
        "    sensitivity_list.append(sensitivity)\n",
        "\n",
        "    # Specificity\n",
        "    specificity = TN / float(TN + FP)\n",
        "    specificity_list.append(specificity)\n",
        "\n",
        "    # MCC (Matthews Correlation Coefficient)\n",
        "    mcc = ((TP * TN) - (FP * FN)) / float((np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))) or 1)\n",
        "    mcc_list.append(mcc)\n",
        "\n",
        "# Calculate average performance evaluation metrics across all folds\n",
        "avg_accuracy = np.mean(accuracy_list)\n",
        "avg_f1 = np.mean(f1_list)\n",
        "avg_precision = np.mean(precision_list)\n",
        "avg_recall = np.mean(recall_list)\n",
        "avg_sensitivity = np.mean(sensitivity_list)\n",
        "avg_specificity = np.mean(specificity_list)\n",
        "avg_mcc = np.mean(mcc_list)\n",
        "\n",
        "# Calculate average AUC across all folds\n",
        "avg_auc = np.mean(auc_list)\n",
        "# Print average performance evaluation metrics\n",
        "print(\"Accuracy =\", avg_accuracy)\n",
        "print(\"F1 Score =\", avg_f1)\n",
        "print(\"Precision =\", avg_precision)\n",
        "print(\"Recall =\", avg_recall)\n",
        "print(\"Sensitivity =\", avg_sensitivity)\n",
        "print(\"Specificity =\", avg_specificity)\n",
        "print(\"MCC =\", avg_mcc)\n",
        "print(\"AUC =\", avg_auc)"
      ],
      "metadata": {
        "id": "EROZNKrOg49m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}